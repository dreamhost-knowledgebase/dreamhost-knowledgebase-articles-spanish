<h2 id="h_01J4HMVQSTC8AHTMHX42WKZ48C">Generalidades</h2>
<div class="solvvy-solution">
<p>Los bots, las spiders y otros crawlers que lleguen a tus páginas dinámicas pueden causar un uso extenso de recursos (memoria y CPU). Esto puede generar una gran carga en el servidor y ralentizar tu(s) sitio(s).</p>
<p>Una opción para reducir la carga del servidor de bots, spiders y otros crawlers es crear un archivo <span class="text-object">robots.txt</span> en la raíz de tu sitio web. Esto le dice a los motores de búsqueda qué contenido en tu sitio deben y no deben indexar. Esto puede ser útil, por ejemplo, si deseas mantener una parte de tu sitio fuera del índice del motor de búsqueda de Google.</p>
<p>Si prefieres no crear este archivo tú mismo, puedes hacer que DreamHost cree uno automáticamente (por dominio) en la página <a class="panel-link" href="https://panel.dreamhost.com/index.cgi?tree=advanced.robots&amp;" target="_blank" rel="noopener noreferrer">Bloquear Spiders</a>.</p>
<div class="notebox-note">
<p>Si bien la mayoría de los principales motores de búsqueda respetan las directivas de <span class="text-object">robots.txt</span>, este archivo solo actúa como una <em>sugerencia</em> para los motores de búsqueda compatibles y no <em>impide</em> que los motores de búsqueda (u otras herramientas similares, como los raspadores de correo/contenido) accedan al contenido o lo hagan disponible.</p>
</div>
</div>
<h2 id="h_01J4HMVQST0VFW8JG51PS8XAGN"><span id="Bloquear_robots">Bloquear robots</span></h2>
<div class="solvvy-solution">
<p>El problema puede ser que Google, Yahoo u otro robot de motor de búsqueda está navegando demasiado en tu sitio. (Este es el tipo de problema que se alimenta a sí mismo; si el bot no puede completar su búsqueda debido a la falta de recursos, puede iniciar la misma búsqueda una y otra vez).</p>
</div>
<h2 id="h_01J4HMVQST407BV2ZKXBM1B711"><span id="Bloquear_Googlebots">Bloquear Googlebots</span></h2>
<div class="solvvy-solution">
<p>En el siguiente ejemplo, la IP de 66.249.66.167 se encontró en tu <a href="https://help.dreamhost.com/hc/es/articles/216512197-Ver-tus-registros-de-acceso-y-error-via-SFTP">access.log</a>. Puedes verificar a qué compañía pertenece esta IP corriendo el comando "host" a través de <a href="https://help.dreamhost.com/hc/es/articles/216041267-Generalidades-de-SSH">SSH</a>:</p>
<div class="preboxcontainer">
<pre class="prebox"><span class="server">[server]$ </span><span class="command">host 66.249.66.167</span>
<span class="cmdoutput">167.66.249.66.in-addr.arpa domain name pointer crawl-66-249-66-167.googlebot.com.</span>
</pre>
</div>
<p>Para bloquear este robot de Google, usa lo siguiente en tu archivo <span class="text-object">robots.txt</span>:</p>
<div class="preboxcontainer">
<pre class="prebox"># go away Googlebot
User-agent: Googlebot
Disallow: /</pre>
</div>
<dl>
<dt>
<h3 id="h_01J4HMVQST7SWG57XQT4QTH71A">Explicación de los campos anteriores:</h3>
</dt>
</dl>
<dl>
<dt><strong># go away</strong></dt>
<dd>Este es un comentario que solo se usa para que sepas por qué creó esta regla.</dd>
<dt><strong>User-agent</strong></dt>
<dd>El nombre del bot al que se aplicará la siguiente regla.</dd>
<dt><strong>Disallow</strong></dt>
<dd>La ruta de la URL que desea bloquear. Esta barra diagonal significa que se bloqueará todo el sitio.</dd>
</dl>
<p>Ve más información sobre los robots de Google haciendo clic en lo siguiente:</p>
<ul>
<li><a href="https://developers.google.com/search/docs/advanced/robots/intro">robots.txt de Google</a></li>
</ul>
</div>
<h2 id="h_01J4HMVQSTJ2F067C2RGFSG17J"><span id="Blquear_Yahoo">Bloquear Yahoo</span></h2>
<div class="solvvy-solution">
<p>Los robots rastreadores de Yahoo cumplen con la regla <span class="code">crawl-delay</span> en <span class="text-object">robots.txt</span> que limita su actividad de recuperación. Por ejemplo, para decirle a Yahoo que no busque una página más de una vez cada 10 segundos, debes agregar lo siguiente:</p>
<div class="preboxcontainer">
<pre class="prebox"># slow down Yahoo
User-agent: Slurp
Crawl-delay: 10</pre>
</div>
<dl>
<dt>
<h3 id="h_01J4HMVQSTY04D1DG2FQPH8MH6">Explicación de los campos anteriores:</h3>
</dt>
</dl>
<dl>
<dt><strong># slow down Yahoo</strong></dt>
<dd>Este es un comentario que solo se usa para que sepas por qué creó esta regla.</dd>
<dt><strong>User-agent: Slurp</strong></dt>
<dd>Slurp es el nombre del agente de usuario de Yahoo. Debes usar esto para bloquear Yahoo.</dd>
<dt><strong>Crawl-delay</strong></dt>
<dd>Le dice al agente de usuario que espere 10 segundos entre cada solicitud al servidor.</dd>
</dl>
<p>Ve más información sobre los robots de Yahoo haciendo clic en lo siguiente:</p>
<ul>
<li><a href="https://help.yahoo.com/kb/search/slurp-crawling-page-sln22600.html">robots.txt de Yahoo</a></li>
</ul>
</div>
<h2 id="h_01J4HMVQSTTCHY06DS89TM5A08"><span id="Retardar_buenos_bots">Retardar buenos bots</span></h2>
<div class="solvvy-solution">
<p>Usa lo siguiente para ralentizar algunos, pero no todos, los buenos bots:</p>
<div class="preboxcontainer">
<pre class="prebox">User-agent: * <br>Crawl-Delay: 10</pre>
</div>
<dl>
<dt>
<h3 id="h_01J4HMVQSTVGWF7DWHGZWRWA6T">Explicación de los campos anteriores:</h3>
</dt>
</dl>
<dl>
<dt><strong>User-agent: *</strong></dt>
<dd>Se aplica a todos los Agentes de usuario.</dd>
<dt><strong>Crawl-delay</strong></dt>
<dd>Le dice al agente de usuario que espere 10 segundos entre cada solicitud al servidor.</dd>
</dl>
<div class="notebox-note">
<p><strong>Googlebot</strong></p>
<p>Revisa las siguientes páginas para obtener más ayuda con Googlebot:</p>
<ul>
<li><a href="https://developers.google.com/search/docs/crawling-indexing/reduce-crawl-rate" target="_blank" rel="noopener noreferrer">Reducir la frecuencia de rastreo del robot de Google</a></li>
<li><a href="https://search.google.com/search-console/googlebot-report" target="_blank" rel="noopener noreferrer">Report a problem with overcrawling</a></li>
</ul>
</div>
</div>
<h2 id="h_01J4HMVQSTSB0Y82CG486NBMG1"><span id="Bloquear_todos_los_bots">Bloquear todos los bots</span></h2>
<div class="solvvy-solution">
<p>Para deshabilitar todos los robots:</p>
<div class="preboxcontainer">
<pre class="prebox">User-agent: *
Disallow: /</pre>
</div>
<p>Para rechazarlos en una carpeta específica:</p>
<div class="preboxcontainer">
<pre class="prebox">User-agent: *
Disallow: /<span class="code-highlight">yourfolder</span>/</pre>
</div>
<dl>
<dd></dd>
<dd></dd>
</dl>
<div class="notebox-important">
<p>Los bots defectuosos pueden usar este contenido como una lista de objetivos.</p>
</div>
<dl>
<dt>
<h3 id="h_01J4HMVQST1WJ410CC5J4J4PAR">Explicación de los campos anteriores:</h3>
</dt>
</dl>
<dl>
<dt><strong>User-agent: *</strong></dt>
<dd>Se aplica a todos los Agentes de usuario.</dd>
<dt><strong>Disallow: /</strong></dt>
<dd>No permite la indexación de todo.</dd>
<dt><strong>Disallow: /yourfolder/</strong></dt>
<dd>No permite la indexación de esta carpeta única.</dd>
</dl>
</div>
<h2 id="h_01J4HMVQST6TVG2Z60BP6TZ2RG"><span id="Usar_precación">Usar precaución</span></h2>
<div class="solvvy-solution">
<p>Si bloqueas todos los bots (User-agent: *) de todo tu sitio (Disallow: /), tu sitio será indexado de los motores de búsqueda legítimos. Además, ten en cuenta que los bots incorrectos probablemente ignorarán tu archivo <span class="text-object">robots.txt</span>, por lo que es posible que desee bloquear tu agente de usuario con un <a href="https://help.dreamhost.com/hc/es/articles/216456227-Generalidades-de-htaccess">archivo .htaccess</a>.</p>
<p>Los robots malos pueden usar tu archivo <span class="text-object">robots.txt</span> como una lista de destino, por lo que es posible que desee omitir los directorios de la lista en el archivo <span class="text-object">robots.txt</span>. Los bots malos también pueden usar agentes de usuario falsos o engañosos, por lo que bloquear agentes de usuario con .htaccess puede no funcionar tan bien como se esperaba.</p>
<p>Si no deseas bloquear a nadie, este es un buen archivo <span class="text-object">robots.txt</span> predeterminado:</p>
<div class="preboxcontainer">
<pre class="prebox">User-agent: *
Disallow:</pre>
</div>
<p>Es posible que debas eliminar el archivo <span class="text-object">robots.txt</span> en este caso, si no te molestan las solicitudes 404 en tus registros.</p>
<p>DreamHost recomienda que solo bloquees agentes de usuario específicos y archivos/directorios, en lugar de *, a menos que estés 100% seguro de que eso es lo que deseas.</p>
</div>
<h2 id="h_01J4HMVQST5PV3Y15DHNSG3H75"><span id="Bloquear_referencias_malas">Bloqueo de referencias malas</span></h2>
<div class="solvvy-solution">
<p>Para obtener instrucciones detalladas, visite el artículo sobre cómo <a href="https://help.dreamhost.com/hc/es/articles/216363197-Prevenir-el-enlace-directo-de-im%C3%A1genes-hotlinking-">bloquear referencias</a>.</p>
</div>
<h2 id="h_01J4HMVQSTZRXP39B6Q2MN5KPP">Ver también</h2>
<div class="solvvy-hidden">
<ul>
<li><a href="https://help.dreamhost.com/hc/es/articles/216041267-Generalidades-de-SSH">Generalidades de SSH</a></li>
<li><a href="https://help.dreamhost.com/hc/es/articles/216456227-Generalidades-de-htaccess">Generalidades de .htaccess</a></li>
<li><a href="https://help.dreamhost.com/hc/es/articles/216512197-Ver-tus-registros-de-acceso-y-error-via-SFTP">Ver tu registro de acceso y error a través de SFTP</a></li>
<li><a href="https://help.dreamhost.com/hc/es/articles/216105097-Ver-y-examinar-tu-access-log-a-trav%C3%A9s-de-SSH">Ver y examinar tu registro de acceso a través de SSH</a></li>
</ul>
</div>
